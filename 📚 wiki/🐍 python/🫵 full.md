### PEP
*Python Enhancement Proposal* - официальный проектный документ, предоставляющий информацию сообществу и описывающий функции Python или его процессов, стиль кода и многое другое, касающееся языка.
*PEP8* - один из самых известный документов в серии. Описывает руководящие принципы написания кода, такие как использование 4 пробелов, длину строки не более чем 79 символов, в каком порядке должны быть выставлены импорты и прочее.
### Интерпретатор компилируемого типа
#### Запуск кода
1. **Компилятор** считывает исходный код и превращает его во внутреннее устройство (своего рода байт-код: **.pyc**)
	- он проверяет синтаксис, отступы, скобки и другие детали
	- не проверяет математику и типизацию
	- байт-код в **__pycache__** не является чистым машинным кодом, только внутреннее представление
2. Это внутреннее представление отправляется в **PVM** (Python Virtual Machine), который построчно транслирует байт-код в машинное представление и исполняет на процессоре
	- предыдущее преобразование делает язык быстрее, потому что базовые задачи обрабатывает компилятор, а интерпретатору нужно только исполнять код
Таким образом, Python должен быть быстрее полностью интерпретируемых языков, однако медленнее, потому что компилирует не в машинный код.
Медленность истекает еще и из того, что в питоне все - **объекты**, из-за чего даже простые операции требуют определения типов налету.
#### Модули и пакеты
**Модуль** - `.py` файлы. 
**Пакеты** - иерархические системы директорий, содержащие модули.
- Простота (работа только над одним отдельным функционалом). Удобство обслуживания (low coupling - меньше связанности между отдельными частями приложения). 
- Возможность повторного использования.
- Разметка (отдельные пространства имен, благодаря чему не будет путаницы о происхождении функций).
#### Импортирование модулей
- При запуске приложение весь код и блок `if __name__ == "__main__":` исполняются единожды
- При повторном импорте того же модуля он будет запускаться, а только возьмется из `sys.modules` при необходимости
### Типы данных и их устройство
#### Неизменяемые типы
##### Примитивные
`int`, `float`, `str`, `bool`, `bytes`, `complex`, `None` - неизменяемые и неделимые объекты.
При этом строки и байты - **плоские последовательности**, т.е. хранят в себе коллекцию данных, при это не ссылками, а по порядку в памяти.
Пустой объект (None) - переменная, которая не содержит значения (`types.NoneType`).
##### Составные
`frozenset`, `tuple` - неизменяемые составные объекты.
Являются **контейнерными последовательностями**. Нельзя поменять, хранятся по порядку в памяти объектами. 
У кортежа память выделяется один раз и не меняется, и выделяется ровно, без запаса. В отличие от списка хранит ссылку на список ссылок на объекты, а не ссылку на ссылку, потому его не нужно удлинять или укорачивать.
#### Изменяемые
`list`, `set`, `dict`, `array.array`, `collections.deque`, `collections.defaultdict` - изменяемые типы данных.
Список, сет, дек - **контейнерные последовательности**.
При этом `array.array` - плоская последоватольность.
**O-большое** - функция для оценки асимптотической сложности (для худшего случая, ограничение сверху, рост времени выполнения функции).
**Список** хранится в памяти как динамический массив. Памяти изначально выделяется больше нужного для амортизации дальнейших вставок. Сжимается, если количество элементов стало меньше половины вместимости. Вставка в конец O(1), но при увеличении размера O(n).
**Сет и словарь** хранятся схоже друг на друга: выделяет определенное количество бакетов, в которые кладутся значения на основе высчитанного хэша. Если слот занят - идет смещение (в оригинале там связный список, но тут оптимизация питона). Если словарь вырос - он расширяется. Поиск по нему - O(1), а вставка O(1), если размера хватает.
**Связный список** - когда каждое следующее значение имеет ссылки на предыдущее.
**Множество** - неупорядоченный список элементов, которые уникальны.
##### Списковые выражения
Работают как синтаксический сахар для создания списков по итерируемым объектам.
С помощью них можно делать фильтрацию:
```python
new_list = [a for a in old_list if a % 2 == 0]
new_generator = (a for a in old_list if a % 2 == 0) # а это уже будет генератор
```
Такое же есть и для словарей:
```python
new_dict = {a: a ** 2 for a in old_list if a % 2 == 0}
```
##### Инфиксные операторы
Операторы +, * и другие должны возвращать новые объекты, не трогая операнды.
##### Сравнение объектов
`==` сравнивает значение объектов.
`is` сравнивает ссылки (указывают ли объекты на ту же область в памяти).
Для примитивных типов работают одинаково.
```python
mas1 = [1, [2], 3]
mas2 = deepcopy(mas1)
mas3 = [1, [2], 3]
print(mas1 == mas2, mas1 == mas3) # True True
print(mas1 is mas2, mas1 is mas3) # False False
```
##### Копирование
В python ‘=’ не копирует объекты, а создает связь между переменной в памяти и названием. Для копирования нужно использовать встроенные функции:
`from copy import copy, deepcopy`
- shallow copy - побитовая копия объекта. Если объект содержит другие объекты внутри, то копируются их ссылки, что не есть хорошо
- deep copy - рекурсивно копирует все объекты (в том числе и вложенные)
##### Хэшируемость
Объект называется хешируемым, если имеет хеш-код, который не изменяется на протяжении всего времени его жизни - у него должен быть метод **__hash__()**, и допускает сравнение с другими объектами - у него должен быть метод **__eq__()**.
Если в результате сравнения хешируемых объектов оказывается, что они равны, то и их хеш-коды должны быть равны.
#### Динамическая и утиная типизации
В питоне нет статической типизации -> типы определяются налету.
**Динамическая** типизация означает, что тип переменной определяется во время выполнения кода, а не на этапе компиляции.
**Утиная** типизация говорит о том, что об объекте можно сделать вывод исходя из его методов. То есть не обязательно, что объект наследуется от какого-то определенного класса, чтобы быть уткой: достаточно, чтобы у него были нужные методы - был нужный **интерфейс**. Это тесно связано с инверсией контроля и протоколами (`typing.Protocol`).
### Выражения
**Литералы** - значение, определяемое в программе: `'1', True, None, {1}, [0], {1: 2}`.
**Выражение** - вычисление, в результате которого получается значение.
```python
a = (x ** 2 for x in [1, 2, 3])     # генераторное выражение
b = [num for num in a if num >= 4]  # списковое включение
c = {num ** 0.5: num for num in b}  # словарное включение
d = {num for num in c}              # включение множества
```
### Функции
Вынесенные участки кода, чтобы сделать переиспользование и тестирование проще и следовать **DRY**.
```python
def fetch_data(*args, **kwargs) -> list: ...  # лучше называть понятно, глаголом

fetch_data(10, "tomato")                 # неименованные аргументу
fetch_data(amount=10, product="tomato")  # именованные аргументы
```
##### Области видимости
1. Сначала идет поиск локально (внутри функции) - **local scope**
2. Потом во внешней функции, если есть - **enclosing** (замыкание)
3. Затем в глобальной области - **global scope**
4. В последнюю очередь - **built-in scope**
`global a` внутри функции будет менять значение переменной из глобальной области видимости.
`nonlocal a` будет менять значение переменной из замыкания.
##### Функции высшего порядка
Это функции, которые принимают в качестве аргументов другие функции. Чаще всего речь идет про функции:
`filter` - первый аргумент - функция фильтрации, второй - итерируемый объект
`map` - применения какой-то функции к итерируемому объекту
`zip` - склеить два объекта (длина будет меньшая)
`reduce` - применить одну функцию между всеми объектами
```python
a = [2, 4, 3, 7, 9, 12, 1, 0]

print(list(filter(lambda x: x > 4, a))) # [7, 9, 12]
print(list(map(lambda x: x ** 2, a))) # квадраты
print(functools.reduce(lambda x, y: x if x >= y else y, a)) # максимум, можно поставить + и получим сумму

from collections import defaultdict  
from functools import partial, wraps  
from itertools import zip_longest  
  
zip_longest  # склеить, но взять длину самого длинного (None у другого)
partial  # вызвать функцию не со всеми аргументами и потом их докинуть
wraps  # обозначить функцию, которая декорирует (сохранить имя)
defaultdict  # если значения нет - вернет то, что передано
```
##### Декораторы
Обертка над функцией. Позволяют добавить поведение функции не изменяя ее саму.
```python
import asyncio  
import time  
import typing as tp  
from functools import wraps  
  
T = tp.TypeVar("T")  
P = tp.ParamSpec("P")  
  
def timer(log_prefix: str) -> tp.Callable[
	[tp.Callable[P, tp.Awaitable[T]]],
	tp.Callable[P, tp.Awaitable[T]]
 ]:  
    def _timer(
	    func: tp.Callable[P, tp.Awaitable[T]]
	) -> tp.Callable[P, tp.Awaitable[T]]:  
        @wraps(func)  # нужно для сохранения имени функции  
        async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:  
            start = time.monotonic()  
            res = await func(*args, **kwargs)  
            print(f"{log_prefix}: {time.monotonic() - start}")  
            return res  
        return wrapper  
    return _timer
```
### Исключения
События, которые влекут за собой ошибку или неправильное выполнение программы. Способ прерывания потока управления.
- `BaseException` - основная ошибка, от которой наследуются все остальные.
- системные - `SystemExit`, `KeyboardInterrupt`, `GeneratorExit`
- обыкновенные - `StopIteration`, `ArithmeticError`, `AssertionError`, `AttributeError`, `ImportError`
```python
try:
	# пробуем выполнить
except (ValueError, TyperError):
	# поймали какую-то ошибку
except Exception:
	# поймали какую-то другую ошибку
else:
	# не поймали ошибку
finally:
	# выполняем что-то независимо от того, поймали ошибку или нет
```
### Классы
```python
class Person:
    __slots__ = ["name"] # ограничение на атрибуты объекта
    work_place: str = "My work place"

    def __init__(self, name: str) -> None:
        self.name = name

    def say_hello(self) -> None: # можно вызвать только из объекта
        print(f"Hello, my name is {self.name}")

    @classmethod
    def print_work_place(cls) -> None: # можно вызвать и из объекта, и из класса
        print(f"{cls.work_place}")
		
	@staticmethod
    def get_some(): # не имеет доступа ни к объекту, ни к классу, просто удобно держать здесь
        print("I'm statuc method")

p = Person()
print(Person.__dict__) # все атрибуты класса
print(p.__dict__) # все атрибуты объекта, т.е. конкретного экзмепляра
```
##### MRO
Method Resolution Order - то, в каком порядке идет поиск метода в родительских классах.
Left -> Right -> Top -> Again
##### Магические методы
__ - дандер методы, помогают реализовать параметрический полиморфизм и перегружать встроенные методы.
##### Создание и инициализация объекта
Метод **__new__()** вызывается при создании нового экземпляра класса.
Он отвечает за выделение памяти под новый объект и возвращает этот объект. Является *classmethod* методом и должен возвращать экземпляр класса.
С другой стороны, метод **__init__()** вызывается после **__new__()**, когда объект уже создан. Он отвечает за инициализацию этого объекта, то есть задаёт начальные значения его атрибутов. И именно поэтому у него внутри уже есть *self*.
##### Абстрактные классы
Определение обязательных методов в дочерних классах.
Не может быть инициализирован.
```python
import abc

class Animal(abc.ABC):
    @abc.abstractmethod
    def run():
        ...
    
class Cat(Animal):
    def run():
        print("Cat is running!")

# a = Animal() # error, method not implemented
c = Cat()
c.run()
```
#### Метаклассы
*Метакласс* - это класс, экземплярами которого являются другие классы. По умолчанию в питоне это *type*.
```python
class SingletonMeta(type):  
    _instances = {}  
    def __call__(cls, *args, **kwargs):  
        if cls not in cls._instances:  
            cls._instances[cls] = super().__call__(*args, **kwargs)  
        return cls._instances[cls]

class Singleton(metaclass=SingletonMeta):
    pass

b1 = Singleton()
b2 = Singleton()
print(b1 is b2) # True
```
### ООП
**Объектно-ориентированное программирование** - представление логики в коде с помощью объектов и их взаимоотношений.
#### Концепции
- **Абстракция** - использование только тех характеристик объекта, которые с точностью определяют его. Нужно представить объект минимальным набором полей и методов, при этом с достаточной точностью для решаемой задачи.
- **Инкапсуляция** - возможность очертить круг связанных функций и данных, которые за пределами этого круга невидимы и доступны только некоторые функции (те самые *public, protected and private*). На самом деле, большинство языков вообще почти не имеют принудительной инкапсуляции. 
```python
class A:
	def public(self):     # доступен отовсюду
		print("публичный")
	def _protected(self): # доступен внутри класса или дочерних
		print("защищенный")
	def __private(self):  # доступен только из класса, но a._A__private()
		print("приватный")
```
* **Наследование** - повторное объявление группы переменных и функций в ограниченной области видимости (переиспользование кода).
* **Полиморфизм** - применение указателей на функции. Т.е. основной код может не зависеть от реализации какого-либо модуля, если этот модуль реализует необходимый интерфейс!
##### Инверсия зависимости
Изменение косвенного потока управления.
Если раньше весь поток управления шел сверху вниз (т.е. от модули высших уровне четко вызывали функции нижних уровней по порядку в одну сторону), то с появлением инверсии зависимости появилась возможность в исходном коде вызывать функции из интерфейса, которая в свою очередь реализована в другом модуле.
Во время самого выполнения кода это не имеет никакого значения, но при построении кода и архитектуры открывает большие возможности.
Что можно с помощью этого сделать? Можно полностью зависеть только от бизнес правил: правила вызывают интерфейсы, а БД и пользовательский интерфейс будут своего рода плагинами, которые этот интерфейс поддерживают.
Таким образом, компонент с БП не будет зависеть от компонентов ПИ и базы данных. Появляется возможность создавать и разворачивать эти компоненты по отдельности, разным командами, и менять реализацию не трогая БП.
```python
from typing import Protocol  # инструмент утиной типизации

class Saver(Protocol):  # БП зависит только от этого
	async def save(self) -> None: ...

class MemorySaver:
	async def save(self) -> None:
		print("saved in memory")

class DBSaver:
	async def save(self) -> None:
		print("saves in database")
```
### Контекстные менеджеры
Позволяют использовать какой-то объект внутри своего контекста, чаще всего, файлы. То есть файл открывается при использовании **with** и закрывается при выходе из него, что облегчает работу, потому что при ошибке и других случаях файл автоматически закроется.
```python
class ContextManager:
    def __enter__(self):  # async def __aenter__
        self.start_time = datetime.datetime.now()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):  # async def __aexit__
        self.end_time = datetime.datetime.now()
        print(self.end_time - self.start_time)

if __name__ == "__main__":
    with ContextManager() as cm:  # async with ...
        time.sleep(2)

@contextlib.contextmanager  # @contextlib.asynccontextmanager
def manager():  
    print("before")  
    yield  
    print("after")
```
### GIL
#### Сборщик мусора
Сборщик мусора автоматически освобождает память, которая больше не используется. Он определяет, что память больше не используется, если на объект нет ссылок.
Таким образом, чтобы освободить память, занимаемую объектом, достаточно удалить все ссылки на него.
Обычный сборщик мусора простой, и не умеет определять циклические ссылки. В таком случае подключается GC. Циклические ссылки могут появляться только в контейнерных объектах: списки, словари и прочее, и именно за такими объектами следит GC.
*Например:* когда внутри списка есть ссылка на этот же список.
Есть `reference count` и `GC`.
**GC** использует поколения:
- новые объекты попадают в 0 поколение и часто проверяются и удаляется (в том числе недостижимые) - после 700 объектов очистка
- объекты, пережившие 0 поколение идут в 1 поколение: оно очищается реже (после 10 чисток 0 поколения)
- если же объект пережил несколько (0 и 1 поколения), то попадает во 2 поколение (после 10 чисток 1 поколения)
```python
import gc

print(gc.get_thresgold())  # (700, 10, 10)
```
#### Глобальная блокировка
**Global Interpreter Lock** - блокировка, позволяющая только одному потоку использовать интерпретатор питона.
Какую же проблемы решает GIL? В питоне освобождение памяти происходит по подсчету ссылок на объект: если на объект счетчик становится равным 0, то его память высвобождается. Проблема в том, что в многопоточном управлении несколько потоков могут увеличивать или уменьшать количество ссылок, из-за чего переменная, необходимая в одном потоке, может быть удалена в другом.
С версии 3.13 начала появляться сборка `--disable-gil`, в которой есть бессмертные объекты и встроенные типы были улучшены для конкурентности (`free-threaded mode`).
### Многопоточность, мультипроцессинг
Процессы служат для запуска и управления программами, тогда как потоки служат для эффективного использования ресурсов и параллельного выполнения задач в рамках одного процесса (в идеальном мире, не питоне).
Функция **fork** модуля **os** создает клон текущего процесса как дочерний процесс. Возвращает 0 в дочернем процессе и идентификатор дочернего процесса в родительском элементе.
##### Синхронизация
-  локи (acquire и release) -  блокировка для выполнения только одного потока
- семафоры - несколько потоков могут одновременно получать доступ (счетчик)
#### Процессы
Отдельные процессы со своими интерпретаторами, поэтому выполняются параллельно.
Не имеют общих переменных, но можно использовать `Queue`:
```python
from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
    p.join()
```
##### Race condition
Неправильное проектирование многопоточной программы, когда результат зависит от того, в каком порядке потоки выполнились. Например, когда два потока пытаются одновременно получить доступ к одной переменной. Можно использовать блокировки для решения проблемы.
#### Потоки
В питоне это **вытесняющая многозадачность**.
Интерпретатор прыгает с потока на поток случайно и выполняет их.
`multithreading` - в момент времени только один поток будет выполняться из-за GIL, но будет видимость многопоточности из-за быстрых переключений и I/O.
### Асинхронность
Концепция, когда результат выполнения функции доступен не сразу, а только по прохождении некоторого количества времени. Удобен тогда, когда функции часто работают с I/O задачами.
**Event loop** - сердце асинхронного приложения, он выполняет асинхронные функции, выполняет переключения между ожиданиями и многое другое. Рядовому разрабу с ним работать не нужно, только тем, кто пишет библиотеки под язык.
Чем отличается от многопоточности?
- требует меньше ресурсов, потому что все происходит в одном потоке
	- нет переключений контекста между потоками, и не нужно держать эти потоки в в операционной системе (кроме `green-thread`)
	- однако при большом количестве корутин будет так же ресурсоемким, потому что нужно управлять всеми задачи в цикле событий
- легче читать и писать код в стиле `async` / `await`
- корутины управляются циклом событий, а не ОС, благодаря чему появляется больше контроля над происходящим
Во время выполнения асинхронного потока есть всего один поток в одном процессе.
- **Coroutine** - сопрограмма, которая написана в специальном синтаксисе (`async def`). Не исполняется сразу, а возвращает объект корутины. Может возвращать и принимать аргументы. Главная фича - можно приостановить ее выполнение.
- **Future** - подобие Promise из JS. Объект, который заверяет, что результат можно будет получить тогда, когда операнд выполнится.
- **Task** - специальный объект, который управляет корутинами, чтобы выполнить код в параллельном режиме. Она создает внутри себя объект Future, чтобы управлять работой и результатом корутины. Наследуется от Future, чтобы с ним можно было работать как с футурой.
##### Базовые конструкции
`async/await` - корутины (функции), которые могут работать асинхронно. Если какая-то функция ждет входа или IO-операцию, то eventpool ищет другой код, который в это время можно выполнить
- `async def` - cоздание корутины, т.е. функции, которую можно приостановить
- `async / await` - синтаксический сахар для вызова и ожидания выполнения функции
`asyncio.gather(*tasks)` - параллельно выполнит все переденные таски.
`asyncio.wait_for(awaitable, timeout)` - если передана корутина, то автоматически она станет таской и будет выполнятся, пока не пройдет время *timeout* в секундах.
### pass / ellipsis
*pass* - когда осознанно нужно показать, что ничего не делаем
*...* - заглушка, которая означает, что нужно что-то реализовать
### Рекурсия
**Рекурсивный процесс** - это процесс с отложенным вычислением.
Т.е. сначала цепочка вызовов дойдет до самого последнего, пока уже не сможет идти дальше, сохраняя при этом весь стек, и уже после этого пойдет наверх, параллельно освобождая стек и проводя вычисления.
Итеративный же процесс не нуждается в выделении памяти вне вызова функции, т.е. все выполняется в одном, явно сохраняя свой “стек”.
```python
def calc_fib(n: int) -> int:
	if n == 1 or n == 2:
		return 1
	return calc_fib(n - 1) + calc_fib(n - 2)
```
### Итераторы и генераторы
**Iterable** - класс, у которого есть iter (по которому можно пройтись, то есть из него можно сделать итератор), но у него нет **__iter__** (на нем можно вызвать iter() и получить итератор).
**Iterator** - класс, у которого есть **__next__** (тот, кто делает реальный проход, сам же может быть Iterable).
**Генераторы** - почти то же самое, только они сохраняют контекст функции (ленивы, поэтому чаще всего не хранят всего внутри, а вычисляют все по необходимости).
```python
class Iterator: # итератор (генератор), который сам генерирует последовательность
    def __init__(self, num):
        self.num = num
        self.idx = -1

    def __iter__(self):
        return self

    def __next__(self):
        self.idx += 1
        if self.idx < self.num:
            return self.idx
        raise StopIteration

class Iterable: # итерируемый объект, из которого можно сделать итератор
    def __init__(self):
        self.seq = [1, 2, 3, 4]

    def __iter__(self):
        return self.seq.__iter__()

i = Iterable()
iterator = iter(i)  # создаем итератор из итерируемого объекта
print(next(iterator))

def generate(): # сопрограмма
    k = 0
    while k < 10:
        i, j = (yield)
        print(i + j)
        k += 1

g = generate()
g.send(None)   # запуск до первого yield
g.send((1, 1)) # запуск после yield
```
***
```python
class Iterator: # итератор (генератор), который сам генерирует последовательность
    def __init__(self, num):
        self.num = num
        self.idx = -1

    def __aiter__(self):
        return self

    async def __anext__(self):
        self.idx += 1
        if self.idx < self.num:
            return self.idx
        raise StopAsyncIteration

class Iterable: # итерируемый объект, из которого можно сделать итератор
    def __init__(self):
        self.seq = Iterator(2)

    def __aiter__(self):
        return self.seq.__aiter__()

async def test():
    i = Iterable()
    iterator = aiter(i)  # создаем итератор из итерируемого объекта
    print(await anext(iterator))

import asyncio
asyncio.run(test())

async def generate(): # асинхронный генератор
    k = 0
    while k < 10:
        i, j = (yield)
        print(i + j)
        k += 1

g = generate()
g.asend(None)   # запуск до первого yield
g.asend((1, 1)) # запуск после yield
```
***
Хороший пример из `httpx.AsyncClient`:
```python
async def _send_handling_auth(  
    self,  
    request: Request,  
    auth: Auth,  
    follow_redirects: bool,  
    history: list[Response],  
) -> Response:  
    auth_flow = auth.async_auth_flow(request)  # создаем генератор (там yield)
    try:  
	    # доходим до первого yield (там запрос должен вернуться обратно)
        request = await auth_flow.__anext__()
  
        while True:  
            response = await self._send_handling_redirects(  
                request,  
                follow_redirects=follow_redirects,  
                history=history,  
            )  
            try:  
                try:  
                    # отправляем ответ в генератор, чтобы проверить там
                    # если все ок - там будет return и выход тут
                    # если же там дальше yield - получаем новый запрос и дальше
                    next_request = await auth_flow.asend(response)  
                except StopAsyncIteration:  
                    return response  
  
                response.history = list(history)  
                await response.aread()  
                request = next_request  
                history.append(response)  
  
            except BaseException as exc:  
                await response.aclose()  
                raise exc  
    finally:  
        await auth_flow.aclose()
```